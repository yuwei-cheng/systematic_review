library(rentrez)
#------------------------------------Data extraction-------------------------------------------------
# Step 1: define MeSH terms and time range
search_term     = "(Japanese Encephalitis [MeSH]) AND (Fatalities OR Fatal OR Mortalities OR Mortal OR Letal OR Lethalities OR Deaths OR Die OR Died OR Dies OR Dead)AND 2018:2020[PDAT]"
fatality_search = entrez_search(db = "pubmed", term = search_term, retmax = 1000)
multi_summary   =  entrez_summary(db = "pubmed", id = fatality_search$ids)
date_and_cite   = extract_from_esummary(multi_summary, c("pubdate","title","articleids"))
date_and_cite
date_and_cite[[3,1]]
dim(date_and_cite)
dim(date_and_cite)[2]
for(i in 1:dim(date_and_cite)[2]) # dim(date_and_cite)[2] is the number of collected articles
{
if((date_and_cite[[3,i]] %>%
subset(idtype=="doi") %>% select(value) %>% unlist() %>% length()) !=0)
{
date_and_cite[[3,i]] <-date_and_cite[[3,i]] %>% # only keep doi
subset(idtype=="doi") %>% select(value) %>% unlist()
}else{date_and_cite[[3,i]] <- NA}
}
library(dplyr)
for(i in 1:dim(date_and_cite)[2]) # dim(date_and_cite)[2] is the number of collected articles
{
if((date_and_cite[[3,i]] %>%
subset(idtype=="doi") %>% select(value) %>% unlist() %>% length()) !=0)
{
date_and_cite[[3,i]] <-date_and_cite[[3,i]] %>% # only keep doi
subset(idtype=="doi") %>% select(value) %>% unlist()
}else{date_and_cite[[3,i]] <- NA}
}
date_and_cite[[3,]]
date_and_cite
date_and_cite[[3,1]]
date_and_cite[[3,2]]
search_result = list()
search_result$pubdate = unlist(t(date_and_cite))[1:dim(date_and_cite)[2]]
search_result$title   = unlist(t(date_and_cite))[(dim(date_and_cite)[2]+1):2*dim(date_and_cite)[2]]
search_result$doi     = unlist(t(date_and_cite))[(2*dim(date_and_cite)[2]+1):3*dim(date_and_cite)[2]]
search_result$EntrezUID = fatality_search$ids
search_result = as.data.frame(search_result)
# 1-28 & 42-47 contains paper after 18 Aug 2018
search_result = search_result %>% arrange(desc(pubdate))
dim(date_and_cite)[2]
2*dim(date_and_cite)[2]
fatality_search$ids
search_result = list()
search_result$pubdate = unlist(t(date_and_cite))[1:dim(date_and_cite)[2]]
search_result$title   = unlist(t(date_and_cite))[(dim(date_and_cite)[2]+1):2*dim(date_and_cite)[2]]
search_result$doi     = unlist(t(date_and_cite))[(2*dim(date_and_cite)[2]+1):3*dim(date_and_cite)[2]]
search_result$EntrezUID = fatality_search$ids
as.data.frame(search_result)
1:dim(date_and_cite)[2]
(dim(date_and_cite)[2]+1):2*dim(date_and_cite)[2]
2*dim(date_and_cite)[2]
(dim(date_and_cite)[2]+1)
(dim(date_and_cite)[2]+1):(2*dim(date_and_cite)[2])
search_result = list()
search_result$pubdate = unlist(t(date_and_cite))[1:dim(date_and_cite)[2]]
search_result$title   = unlist(t(date_and_cite))[(dim(date_and_cite)[2]+1):(2*dim(date_and_cite)[2])]
search_result$doi     = unlist(t(date_and_cite))[(2*dim(date_and_cite)[2]+1):(3*dim(date_and_cite)[2])]
search_result$EntrezUID = fatality_search$ids
search_result = as.data.frame(search_result)
search_result = search_result %>% arrange(desc(pubdate))
search_result
library(XML)
extract_abstract_func = function(pm_data)
{
PM_id = pm_data$EntrezUID
fetch_pubmed = entrez_fetch(db = "pubmed", id = PM_id,rettype = "xml", parsed = T)
abstracts = xpathApply(fetch_pubmed, '//PubmedArticle//Article',
function(x) xmlValue(xmlChildren(x)$Abstract))
# is used to apply a function to each
# of those nodes, e.g. find nodes named "a anywhere in the tree that have
# an "href" attribute and get the value
# of that attribute
names(abstracts) = PM_id
col_abstracts = do.call(rbind, abstracts) # rbind every elements inside abstracts
abstract_avai = cbind(as.character(pm_data[!is.na(col_abstracts),"title"]),
as.character(pm_data[!is.na(col_abstracts),"doi"]),
as.character(pm_data[!is.na(col_abstracts),"pubdate"]),
as.character(pm_data[!is.na(col_abstracts),"EntrezUID"]),
col_abstracts[!is.na(col_abstracts),])
colnames(abstract_avai) = c("TITLE","DOI","PUBDATE","ENTREZUID","ABSTRACT")
abstract_na <- pm_data[is.na(col_abstracts),]
return(list(abstract_avai, abstract_na))
}
fatality_abstract = extract_abstract_func(search_result)
fatality_abstract
write.csv(x = fatality_abstract[[1]],
file = "./outputs/fatality_abstract_18_to_20.csv",
row.names = F)
write.csv(x = fatality_abstract[[2]],
file = "./outputs/fatality_abstract_NA_18_to_20.csv",
row.names = F)
library(metagear)     # Paper screening
invisible(effort_distribute(fatality_abstract[[1]], initialize = TRUE,
reviewers = "yuwei", save_split = TRUE,
directory = "./outputs/paper_screening/"))
abstract_screener("./outputs/paper_screening/effort_yuwei.csv", aReviewer = "yuwei")
abstract_screener("./outputs/paper_screening/effort_yuwei.csv", aReviewer = "yuwei")
paper_to_collect = read.csv("./outputs/paper_screening/effort_yuwei.csv")
paper_to_collect = paper_to_collect %>% subset(INCLUDE=="YES")
collection_outcomes = PDFs_collect(paper_to_collect, DOIcolumn = "DOI",
FileNamecolumn = "ENTREZUID", quiet = TRUE,
directory = "./outputs/paper_screening/")
collection_outcomes
collection_outcomes$downloadOutcomes
collection_outcomes$downloadOutcomes
dim(collection_outcomes)
names(collection_outcomes)
collection_outcomes$downloadOutcomes
collection_outcomes$STUDY_ID[collection_outcomes$downloadOutcomes != "downloaded"]
mannual_extract = collection_outcomes$STUDY_ID[collection_outcomes$downloadOutcomes != "downloaded"]
paper_to_collect %>% subset(STUDY_ID %in% mannual_extract) %>% select(TITLE,ENTREZUID)
mannaul_collect = paper_to_collect %>%
subset(STUDY_ID %in% mannual_extract) %>%
select(TITLE,ENTREZUID)
rm(mannaul_collect)
sink("./outputs/mannual_collection.csv")
paper_to_collect %>% subset(STUDY_ID %in% mannual_extract) %>% select(TITLE,ENTREZUID)
sink()
sink("./outputs/mannual_collection.txt")
paper_to_collect %>% subset(STUDY_ID %in% mannual_extract) %>% select(TITLE,ENTREZUID)
sink()
collection_outcomes = PDFs_collect(paper_to_collect, DOIcolumn = "DOI",
FileNamecolumn = "ENTREZUID", # save file name and entrez id
quiet = TRUE,
directory = "./paper") # directory to save your paper
#---------------------------------------Directory---------------------------------------------------
folderdir = "outputs/tb/" # folder directory for that project
if(!require('rentrez')) install.packages('rentrez'); library(rentrez)
if(!require('dplyr')) install.packages('dplyr'); library(dplyr)
if(!require('XML')) install.packages('XML'); library(XML)
if(!require('metagear')) install.packages('metagear'); library(metagear)
#---------------------------------------Directory---------------------------------------------------
folderdir = "outputs/tb/" # folder directory for that project
reviewer = "jem"
#------------------------------------Data extraction------------------------------------------------
# Define MeSH terms and time range
search_term     = "(Tuberculosis projections) AND (Case rates OR incidence OR population) AND 2015:2020[PDAT]"
search          = entrez_search(db = "pubmed", term = search_term, retmax = 100)
View(search)
search          = entrez_search(db = "pubmed", term = search_term, retmax = 200)
View(search)
multi_summary   =  entrez_summary(db = "pubmed", id = search$ids)
date_and_cite   = extract_from_esummary(multi_summary, c("pubdate","title","articleids"))
#--------------------------------------------------------------------------------------------------
source('codes/01 screening_abstract.R')
source('codes/02 collect_pdf.R')
if(!file.exists(paste0(folderdir, 'papers/'))) dir.create(paste0(folderdir, 'papers/'))
paper_to_collect = read.csv(path_effort)
paper_to_collect = paper_to_collect %>% subset(INCLUDE=="YES")
paper_to_collect
i = 1
PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")) # directory to save your paper
collection_outcomes = data.frame(paper_to_collect, Error = 0)
temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")) # directory to save your paper
temp
View(temp)
i = 7
temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")) # directory to save your paper
View(temp)
try
?try
try(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")))
?tryCatch
# temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
#                     FileNamecolumn = "TITLE", # save file name and entrez id
#                     quiet = TRUE,
#                     directory = paste0(folderdir, "papers"))
temp = tryCatch(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")), # directory to save your paper
error = function(e) {
next
})
View(temp)
names(temp)
collection_outcomes = data.frame(paper_to_collect, downloadOutcomes = 0)
for(i in 1:nrow(paper_to_collect)){
# temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
#                     FileNamecolumn = "TITLE", # save file name and entrez id
#                     quiet = TRUE,
#                     directory = paste0(folderdir, "papers"))
temp = tryCatch(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")), # directory to save your paper
error = function(e) {
print(e)
next
})
collection_outcomes[i, ] = temp[i, ]
}
View(collection_outcomes)
collection_outcomes = data.frame(paper_to_collect, downloadOutcomes = 0)
for(i in 1:nrow(paper_to_collect)){
# temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
#                     FileNamecolumn = "TITLE", # save file name and entrez id
#                     quiet = TRUE,
#                     directory = paste0(folderdir, "papers"))
result = tryCatch(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")), # directory to save your paper
error = function(e) {
print(e)
return("error")
next
})
print(i)
print(result)
#collection_outcomes[i, ] = temp[i, ]
}
for(5 in 1:nrow(paper_to_collect)){
# temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
#                     FileNamecolumn = "TITLE", # save file name and entrez id
#                     quiet = TRUE,
#                     directory = paste0(folderdir, "papers"))
if_error = tryCatch(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")), # directory to save your paper
error = function(e) {
print(e)
return("error")
next
})
print(i)
if(if_error != 'error'){
print('save')
}
#print(result)
#collection_outcomes[i, ] = temp[i, ]
}
for(i in 5:nrow(paper_to_collect)){
print(i)
# temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
#                     FileNamecolumn = "TITLE", # save file name and entrez id
#                     quiet = TRUE,
#                     directory = paste0(folderdir, "papers"))
if_error = tryCatch(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")), # directory to save your paper
error = function(e) {
print(e)
return("error")
next
})
if(if_error != 'error'){
print('save')
} else {
print ('Error bro!')
}
#print(result)
#collection_outcomes[i, ] = temp[i, ]
}
collection_outcomes = data.frame(paper_to_collect, downloadOutcomes = 0)
View(temp)
names(temp)
names(collection_outcomes)
collection_outcomes = data.frame(paper_to_collect, downloadOutcomes = 0)
for(i in 5:nrow(paper_to_collect)){
print(i)
# temp = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
#                     FileNamecolumn = "TITLE", # save file name and entrez id
#                     quiet = TRUE,
#                     directory = paste0(folderdir, "papers"))
# first identify if its an error, if its not, then save the results
if_error = tryCatch(PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers")), # directory to save your paper
error = function(e) {
print(e)
return("error")
next
})
# saving non-error results
if(if_error != 'error'){
collection_outcomes[i, ] = PDFs_collect(paper_to_collect[i, ], DOIcolumn = "DOI",
FileNamecolumn = "TITLE", # save file name and entrez id
quiet = TRUE,
directory = paste0(folderdir, "papers"))
} else {
# saving error results
print ('Error bro!')
collection_outcomes[i, 'downloadOutcomes'] = 'loop error'
}
}
View(collection_outcomes)
?PDFs_collect
if(!file.exists(paste0(folderdir, 'papers/'))) dir.create(paste0(folderdir, 'papers/'))
folderdir = "outputs/tb/"
reviewer = "jem"
if(!file.exists(paste0(folderdir, 'papers/'))) dir.create(paste0(folderdir, 'papers/'))
paper_to_collect = read.csv(path_effort)
paper_to_collect = paper_to_collect %>% subset(INCLUDE=="YES")
path_effort
#--------------------------------------Screening abstracts------------------------------------------
# An API will pop up, select Yes, Maybe, or No
path_effort = paste0(folderdir, "outputs/effort_", reviewer, ".csv")
paper_to_collect = read.csv(path_effort)
getwd()
paper_to_collect = read.csv(path_effort)
path_effort
paper_to_collect = read.csv(path_effort, header = TRUE, sep = ',')
getConnection()
?getConnection()
?getConnection
path_effort
getwd()
path_effort = paste0('/', folderdir, "outputs/effort_", reviewer, ".csv")
if(!file.exists(paste0(folderdir, 'papers/'))) dir.create(paste0(folderdir, 'papers/'))
paper_to_collect = read.csv(path_effort, header = TRUE, sep = ',')
path_effort
